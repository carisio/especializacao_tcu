{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caderno de teste - Métricas\n",
    "\n",
    "Fontes:\n",
    "\n",
    "- https://huggingface.co/spaces/evaluate-metric/trec_eval\n",
    "\n",
    "- https://github.com/joaopalotti/trectools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 1 - Execução simples testando uma query\n",
    "\n",
    "Vamos supor que o qrel da query 0 indica 3 documentos, doc_1, doc_2 e doc_3, cujas relevâncias são 3, 2, 1.\n",
    "\n",
    "O sistema de busca retornou, nessa ordem, doc_2, doc_1, doc_10, doc_11, doc_12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "trec_eval = load(\"trec_eval\")\n",
    " \n",
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_10\", \"doc_11\", \"doc_12\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 2, 3, 4], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2, 1.1, 1, 0.9], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ver o que ocorre se tirarmos os três documentos não relevantes (não pode mudar nada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando o efeito do score no qrels (só pode mudar o ndcg, mas a precisão tem que continuar a mesma):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.777975983841851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [10, 9, 8]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos alterar novamente o score no qrel, mas para 30, 20, 10 (mantém a mesma proporção que 3, 2, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [30, 20, 10]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [1.5, 1.2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver se o score no run faz algum efeito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [0, 1000], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As conclusões aqui:\n",
    "\n",
    "- O score no qrel fazem diferença pro nDCG. Uma relação de 2/1 no score do qrel equivale a uma relação de 6/2. A relação entre os scores no qrel parece ser multiplicativa.\n",
    "\n",
    "- O score no run parece não fazer diferença para o nDCG. Mesmo mudando a ordem (colocando um score mais alto para quem está mais atrás no ranking) não faz diferença nos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2 - Execução testando uma query e dois sistemas\n",
    "\n",
    "Vamos supor que o qrel da query 0 indica 3 documentos, doc_1, doc_2 e doc_3, cujas relevâncias são 3, 2, 1.\n",
    "\n",
    "O sistema 1 retornou, nessa ordem, doc_2, doc_1.\n",
    "\n",
    "O sistema 2 retornou apenas doc_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.9224945116765986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\", \"sistema2\"] # SISTEMA\n",
    "}\n",
    " \n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado não é o que queremos e dá pra ver isso na precisão.\n",
    "\n",
    "Estou interpretando \"system\" como um sistema, então quero o resultado por sistema. \n",
    "\n",
    "O que eu esperava aqui é ter uma precisão/ndcg para o sistema 1 e uma precisão/ndcg para o sistema 2. Vamos tentar separar o run em dois, run_sistema_1 e run_sistema_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa abordagem não dá certo\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run_sistema_1 = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\"] # SISTEMA\n",
    "}\n",
    " \n",
    "run_sistema_2 = {\n",
    "    \"query\": [0], # QUERY ID\n",
    "    \"q0\": [\"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema2\"] # SISTEMA\n",
    "}\n",
    "\n",
    "try:\n",
    "    results = trec_eval.compute(predictions=[run_sistema_1, run_sistema_2], references=[qrel])\n",
    "    print(results['P@5'])\n",
    "    print(results['NDCG@5'])\n",
    "except:\n",
    "    print('Essa abordagem não dá certo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O jeito parece ser separar e rodar duas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.8174935137996165\n",
      "******************************\n",
      "0.2\n",
      "0.21000199575396408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1]\n",
    "    }\n",
    "run_sistema_1 = {\n",
    "    \"query\": [0, 0], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema1\", \"sistema1\"] # SISTEMA\n",
    "}\n",
    " \n",
    "run_sistema_2 = {\n",
    "    \"query\": [0], # QUERY ID\n",
    "    \"q0\": [\"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_3\"], # DOCUMENT_ID\n",
    "    \"rank\": [0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"sistema2\"] # SISTEMA\n",
    "}\n",
    "\n",
    "results_sistema_1 = trec_eval.compute(predictions=[run_sistema_1], references=[qrel])\n",
    "results_sistema_2 = trec_eval.compute(predictions=[run_sistema_2], references=[qrel])\n",
    "print(results_sistema_1['P@5'])\n",
    "print(results_sistema_1['NDCG@5'])\n",
    "print('*'*30)\n",
    "print(results_sistema_2['P@5'])\n",
    "print(results_sistema_2['NDCG@5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 3: agregando queries diferentes para um sistema\n",
    "\n",
    "Agora que sabemos como a ferramenta trata sistemas diferentes (é necessário executar separadamente), vamos ver como é o tratamento com mais de uma query. Vamos testar 3 queries:\n",
    "\n",
    "O qrel de cada query está assim:\n",
    "\n",
    "- query 0\n",
    "    - docs: doc_1, doc_2, doc_3\n",
    "    - relevância: 3, 2, 1\n",
    "\n",
    "- query 1\n",
    "    - docs: doc_1, doc_5, doc_6\n",
    "    - relevância: 3, 2, 1\n",
    "\n",
    "- query 2\n",
    "    - docs: doc_3\n",
    "    - relevância: 3\n",
    "\n",
    "O sistema de busca retornou:\n",
    "\n",
    "- query 0:\n",
    "    - docs: doc_1, doc_2 (P@5 = 2/5 = 0.4)\n",
    "- query 1:\n",
    "    - docs: doc_5 (P@5 = 1/5 = 0.2)\n",
    "- query 2:\n",
    "    - docs: não retornou nada (P@5 = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a query 2 não retornou nada, vou fazer o primeiro teste sem passar ela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.6187487526537724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A média dos P@5 deve ser de (0.4 + 0.2 + 0)/3 = 0.2.\n",
    "\n",
    "Como não passamos a query 2, ele desconsiderou-a da métrica. Assim, mesmo que não tenha resultados, é necessário informá-la de alguma forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20000000000000004\n",
      "0.4124991684358483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1, 2], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\", \"\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0, -1], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2, -1], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passando vazio no docid e -1 no rank/score funcionou. O mesmo ocorre passando alguma string inexistente no docid e qualquer outro número no rank/score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20000000000000004\n",
      "0.4124991684358483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carisiof\\AppData\\Local\\anaconda3\\envs\\especializacao\\lib\\site-packages\\trectools\\trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    }
   ],
   "source": [
    "qrel = {\n",
    "    \"query\": [0, 0, 0, 1, 1, 1, 2],\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\", \"q0\"],\n",
    "    \"docid\": [\"doc_1\", \"doc_2\", \"doc_3\", \"doc_1\", \"doc_5\", \"doc_6\", \"doc_3\"],\n",
    "    \"rel\": [3, 2, 1, 3, 2, 1, 3]\n",
    "    }\n",
    "run = {\n",
    "    \"query\": [0, 0, 1, 2], # QUERY ID\n",
    "    \"q0\": [\"q0\", \"q0\", \"q0\", \"q0\"], # LITERAL q0\n",
    "    \"docid\": [\"doc_2\", \"doc_1\", \"doc_5\", \"XXXXXXX\"], # DOCUMENT_ID\n",
    "    \"rank\": [0, 1, 0, 0], # RANKING DO DOCUMENTO\n",
    "    \"score\": [2, 1, 2, 0], # SCORE DO DOCUMENTO\n",
    "    \"system\": [\"test\", \"test\", \"test\", \"test\"] # SISTEMA\n",
    "}\n",
    " \n",
    "results = trec_eval.compute(predictions=[run], references=[qrel])\n",
    "print(results['P@5'])\n",
    "print(results['NDCG@5'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "especializacao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
