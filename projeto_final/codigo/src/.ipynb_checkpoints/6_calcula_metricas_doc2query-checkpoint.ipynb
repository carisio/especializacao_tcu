{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caderno 6 - Calcula métricas considerando os resultados de pesquisa em um BM25 com expansão de documentos com doc2query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se True, refaz a indexação. Se False, tenta recuperar o\n",
    "# índice do arquivo indice_js_enunciado_e_excerto.pickle.\n",
    "# É necessário que esse arquivo exista.\n",
    "REINDEXAR_ENUNCIADO_EXCERTO_DOC2QUEY = False\n",
    "\n",
    "PASTA_DADOS = './dados/'\n",
    "PASTA_RESULTADO_CADERNO = f'{PASTA_DADOS}outputs/6_metricas_bm25_com_doc2query/'\n",
    "NOME_ARQUIVO_INDICE_ENUNCIADO_EXCERTO_E_DOC2QUERY = f'{PASTA_RESULTADO_CADERNO}indice_js_enunciado_e_excerto_e_doc2query.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carrega base de dados\n",
    "\n",
    "Carrega a lista de documentos para indexar, as queries para testar e o qrels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# A pasta dos JURIS aqui não é a pasta original, e sim o resultado do caderno 1 (os documentos já estão filtrados)\n",
    "PASTA_JURIS_TCU = f'{PASTA_DADOS}outputs/1_tratamento_juris_tcu/'\n",
    "\n",
    "# Carrega os arquivos \n",
    "def carrega_juris_tcu():\n",
    "    doc1 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_1.csv', sep='|')\n",
    "    doc2 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_2.csv', sep='|')\n",
    "    doc3 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_3.csv', sep='|')\n",
    "    doc4 = pd.read_csv(f'{PASTA_JURIS_TCU}doc_tratado_parte_4.csv', sep='|')\n",
    "    doc = pd.concat([doc1, doc2, doc3, doc4], ignore_index=True)\n",
    "    query = pd.read_csv(f'{PASTA_JURIS_TCU}query_tratado.csv', sep='|')\n",
    "    qrel = pd.read_csv(f'{PASTA_JURIS_TCU}qrel_tratado.csv', sep='|')\n",
    "\n",
    "    return doc, query, qrel\n",
    "\n",
    "docs, queries, qrels = carrega_juris_tcu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega a expansão das queries gerada no caderno anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "PASTA_CADERNO_DOC2QUERY = f'{PASTA_DADOS}outputs/5_doc2query/'\n",
    "NOME_ARQUIVO_DOC2QUERY = f'{PASTA_CADERNO_DOC2QUERY}doc2query.pickle'\n",
    "\n",
    "# Fazemos o caminho inverso aqui:\n",
    "with open(NOME_ARQUIVO_DOC2QUERY, 'rb') as f:\n",
    "    queries_por_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insere a informação do doc2query no dataframe de documentos. Se o doc2query tiver gerado queries idênticas, desconsidera as duplicadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['DOC2QUERY'] = docs['KEY'].map(lambda key: \" \".join(set(queries_por_doc[key])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instancia um BM25 e indexa os campos ENUNCIADO e EXCERTO e as queries expandidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm25 import IndiceInvertido, BM25, tokenizador_pt\n",
    "import re\n",
    "\n",
    "# Função para remover tags HTML\n",
    "def remove_html(html):\n",
    "  return re.sub(\"<[^>]*>\", \"\", html).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Vamos criar um índice invertido e indexar apenas o enunciado e excerto.\n",
    "iidx = IndiceInvertido(lambda texto: tokenizador_pt(remove_html(texto)))\n",
    "\n",
    "if REINDEXAR_ENUNCIADO_EXCERTO_DOC2QUEY or not os.path.exists(NOME_ARQUIVO_INDICE_ENUNCIADO_EXCERTO_E_DOC2QUERY):\n",
    "    # Se for indexar a primeira vez:\n",
    "    # Demora cerca de XX minutos para indexar\n",
    "    iidx.adiciona_dataframe(docs, lambda row: (row['KEY'], row['ENUNCIADO'] + ' ' + row['EXCERTO'] + ' ' + row['DOC2QUERY'])\n",
    "    iidx.to_pickle(NOME_ARQUIVO_INDICE_ENUNCIADO_EXCERTO_E_DOC2QUERY)\n",
    "else:\n",
    "    # Se quiser recuperar de um arquivo:\n",
    "    iidx.from_pickle(NOME_ARQUIVO_INDICE_ENUNCIADO_EXCERTO_E_DOC2QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora instancia um BM25\n",
    "buscador = BM25(iidx, k1=0.82, b=0.68, bias_idf=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Faz as pesquisas e salva os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_resultado_query_key=[]\n",
    "col_resultado_doc_key=[]\n",
    "col_resultado_rank=[]\n",
    "\n",
    "for i, row in queries.iterrows():\n",
    "    query_key = row.KEY\n",
    "    query_text = row.TEXT\n",
    "    resultados = buscador.pesquisar(query_text)\n",
    "\n",
    "    primeiros_50_docs = [tupla_key_score[0] for tupla_key_score in resultados[:50]]\n",
    "    queries_keys = [query_key] * len(primeiros_50_docs)\n",
    "    ranking = list(range(1, len(primeiros_50_docs)+1))\n",
    "\n",
    "    col_resultado_query_key.extend(queries_keys)\n",
    "    col_resultado_doc_key.extend(primeiros_50_docs)\n",
    "    col_resultado_rank.extend(ranking)\n",
    "\n",
    "df_resultados = pd.DataFrame({\n",
    "    \"QUERY_KEY\": col_resultado_query_key,\n",
    "    \"DOC_KEY\": col_resultado_doc_key,\n",
    "    \"RANK\": col_resultado_rank,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metricas import metricas\n",
    "\n",
    "df_metricas = metricas(df_resultados, qrels, aproximacao_trec_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metricas import histograma_metricas, boxplot_metricas\n",
    "\n",
    "# Resultados para o primeiro grupo de queries:\n",
    "display(df_metricas[0:50].describe())\n",
    "histograma_metricas(df_metricas[0:50])\n",
    "boxplot_metricas(df_metricas[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o primeiro grupo de queries:\n",
    "display(df_metricas[50:100].describe())\n",
    "histograma_metricas(df_metricas[50:100])\n",
    "boxplot_metricas(df_metricas[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o primeiro grupo de queries:\n",
    "display(df_metricas[100:150].describe())\n",
    "histograma_metricas(df_metricas[100:150])\n",
    "boxplot_metricas(df_metricas[100:150])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
